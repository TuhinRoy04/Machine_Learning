{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n",
      "Found 372 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 20s 252ms/step - loss: 0.8849 - accuracy: 0.5563 - val_loss: 0.4785 - val_accuracy: 0.9435\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 19s 244ms/step - loss: 0.2515 - accuracy: 0.9087 - val_loss: 0.2688 - val_accuracy: 0.9597\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 20s 250ms/step - loss: 0.1046 - accuracy: 0.9623 - val_loss: 0.3906 - val_accuracy: 0.9489\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 19s 247ms/step - loss: 0.0731 - accuracy: 0.9722 - val_loss: 0.0707 - val_accuracy: 0.9489\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 19s 247ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.0018 - val_accuracy: 0.9516\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 20s 248ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.2227 - val_accuracy: 0.9543\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 19s 246ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0021 - val_accuracy: 0.9543\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 20s 248ms/step - loss: 0.0498 - accuracy: 0.9817 - val_loss: 0.0057 - val_accuracy: 0.9543\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 19s 246ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.0127 - val_accuracy: 0.9704\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 19s 244ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.0830 - val_accuracy: 0.9624\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 19s 244ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0396 - val_accuracy: 0.9543\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 20s 247ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0686 - val_accuracy: 0.9677\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 19s 246ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.1621 - val_accuracy: 0.9597\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 19s 245ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.2618 - val_accuracy: 0.9570\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 19s 243ms/step - loss: 0.0112 - accuracy: 0.9956 - val_loss: 6.3510e-04 - val_accuracy: 0.9677\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 19s 245ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.1683 - val_accuracy: 0.9624\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 19s 246ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9624\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 20s 247ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.2377 - val_accuracy: 0.9570\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 19s 245ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 1.8286e-05 - val_accuracy: 0.9597\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 20s 249ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.2258 - val_accuracy: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22850393448>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "train_set=train_datagen.flow_from_directory('C:/Users/Tuhin Roy/Downloads/Rock-Paper-Scissors/train',batch_size=32,class_mode='categorical',target_size=(64,64))\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_set=test_datagen.flow_from_directory('C:/Users/Tuhin Roy/Downloads/Rock-Paper-Scissors/test',batch_size=32,class_mode='categorical',target_size=(64,64))\n",
    "cnn=Sequential()\n",
    "cnn.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",input_shape=[64,64,3]))\n",
    "cnn.add(MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "cnn.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "cnn.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "cnn.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=(3,3),strides=(2,2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(units=128,activation=\"relu\"))\n",
    "cnn.add(Dense(units=3,activation=\"softmax\"))\n",
    "cnn.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "cnn.fit_generator(train_set,epochs=20,validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result : Paper\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "path=\"C:/Users/Tuhin Roy/Downloads/Rock-Paper-Scissors/validation/paper-hires2.png\"\n",
    "images = image.load_img(path,target_size=(64,64))\n",
    "images = image.img_to_array(images)\n",
    "images = np.expand_dims(images,axis=0)\n",
    "prediction = cnn.predict(images)\n",
    "train_set.class_indices\n",
    "if (prediction[0,0] == 1):\n",
    "    print(\"Result : Paper\")\n",
    "elif(prediction[0,1] == 1):\n",
    "    print(\"Result : Rock\")\n",
    "else:\n",
    "    print(\"Result : Scissor\")\n",
    "test_image=cv2.imread(path)\n",
    "window_name='Rock_Paper_Scissor'\n",
    "cv2.imshow(window_name,test_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
